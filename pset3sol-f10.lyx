#LyX 1.6.5 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble

\renewcommand{\vec}[1]{\mathbf{#1}}

\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand{\labelenumii}{(\roman{enumii})}

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}
\end_preamble
\use_default_options false
\language english
\inputencoding auto
\font_roman times
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 2
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\topmargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Section*
18.335 Problem Set 3 Solutions
\end_layout

\begin_layout Subsection*
Problem 1: SVD and low-rank approximations (5+10+10+10 pts)
\end_layout

\begin_layout Enumerate
\begin_inset Formula $A=\hat{Q}\hat{R}$
\end_inset

, where the columns of 
\begin_inset Formula $\hat{Q}$
\end_inset

 are orthonormal and hence 
\begin_inset Formula $\hat{Q}^{*}\hat{Q}=I$
\end_inset

.
 Therefore, 
\begin_inset Formula $A^{*}A=(\hat{Q}\hat{R})^{*}(\hat{Q}\hat{R})=\hat{R}^{*}(\hat{Q}^{*}\hat{Q})\hat{R}=\hat{R}^{*}\hat{R}$
\end_inset

.
 But the singular values of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $\hat{R}$
\end_inset

 are the square roots of the nonzero eigenvalues of 
\begin_inset Formula $A^{*}A$
\end_inset

 and 
\begin_inset Formula $\hat{R}^{*}\hat{R}$
\end_inset

, respectively, and since these two matrices are the same the singular values
 are the same.
 Q.E.D.
\end_layout

\begin_layout Enumerate
It is sufficient to show that the reduced SVD 
\begin_inset Formula $A\hat{V}=\hat{U}\hat{\Sigma}$
\end_inset

 is real, since the remaining columns of 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 are formed as a basis for the orthogonal complement of the columns of 
\begin_inset Formula $\hat{U}$
\end_inset

 and 
\begin_inset Formula $\hat{V}$
\end_inset

, and if the latter are real then their complement is obviously also real.
 Furthermore, it is sufficient to show that 
\begin_inset Formula $\hat{U}$
\end_inset

 can be chosen real, since 
\begin_inset Formula $A^{*}u_{i}/\sigma_{i}=v_{i}$
\end_inset

 for each column 
\begin_inset Formula $u_{i}$
\end_inset

 of 
\begin_inset Formula $\hat{U}$
\end_inset

 and 
\begin_inset Formula $v_{i}$
\end_inset

 of 
\begin_inset Formula $\hat{U}$
\end_inset

, and 
\begin_inset Formula $A^{*}$
\end_inset

 is real.
 The columns 
\begin_inset Formula $u_{i}$
\end_inset

 are eigenvectors of 
\begin_inset Formula $A^{*}A=B$
\end_inset

, which is a real-symmetric matrix, i.e.
 
\begin_inset Formula $Bu_{i}=\sigma_{i}^{2}u_{i}$
\end_inset

.
 Suppose that the 
\begin_inset Formula $u_{i}$
\end_inset

 are 
\emph on
not
\emph default
 real.
 Then the real and imaginary parts of 
\begin_inset Formula $u_{i}$
\end_inset

 are themselves eigenvectors with eigenvalue 
\begin_inset Formula $\sigma_{i}^{2}$
\end_inset

 (proof: take the real and imaginary parts of 
\begin_inset Formula $Bu_{i}=\sigma_{i}^{2}u_{i}$
\end_inset

, since 
\begin_inset Formula $B$
\end_inset

 and 
\begin_inset Formula $\sigma_{i}^{2}$
\end_inset

 are real).
 Hence, taking either the real or imaginary parts of the complex 
\begin_inset Formula $u_{i}$
\end_inset

 (whichever is nonzero) and normalizing them to unit length, we obtain a
 new purely real 
\begin_inset Formula $\hat{U}$
\end_inset

.
 Q.E.D.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
There is a slight wrinkle if there are repeated eigenvalues, e.g.
 
\begin_inset Formula $\sigma_{1}=\sigma_{2}$
\end_inset

, because the real or imaginary parts of 
\begin_inset Formula $u_{1}$
\end_inset

 and 
\begin_inset Formula $u_{2}$
\end_inset

 might not be orthogonal.
 However, taken together, the real and imaginary parts of any multiple eigenvalu
es must span the same space, and hence we can find a real orthonormal basis
 with Gram-Schmidt or whatever.
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
We just need to show that, for any 
\begin_inset Formula $A\in\mathbb{C}^{m\times n}$
\end_inset

 with rank 
\begin_inset Formula $<n$
\end_inset

 and for any 
\begin_inset Formula $\epsilon>0$
\end_inset

, we can find a full-rank matrix 
\begin_inset Formula $B$
\end_inset

 with 
\begin_inset Formula $\Vert A-B\Vert_{2}<\epsilon$
\end_inset

.
 Form the SVD 
\begin_inset Formula $A=U\Sigma V^{*}$
\end_inset

 with singular values 
\begin_inset Formula $\sigma_{1},\ldots,\sigma_{r}$
\end_inset

 where 
\begin_inset Formula $r<n$
\end_inset

 is the rank of 
\begin_inset Formula $A$
\end_inset

.
 Let 
\begin_inset Formula $B=U\tilde{\Sigma}V^{*}$
\end_inset

 where 
\begin_inset Formula $\tilde{\Sigma}$
\end_inset

 is the same as 
\begin_inset Formula $\Sigma$
\end_inset

 except that it has 
\begin_inset Formula $n-r$
\end_inset

 additional nonzero singular values 
\begin_inset Formula $\sigma_{k>r}=\epsilon/2$
\end_inset

.
 From equation 5.4 in the book, 
\begin_inset Formula $\Vert B-A\Vert_{2}=\sigma_{r+1}=\epsilon/2<\epsilon$
\end_inset

, noting that 
\begin_inset Formula $A=B_{r}$
\end_inset

 in the notation of the book.
 
\end_layout

\begin_layout Enumerate
Take any grayscale photograph (either one of your own, or off the web).
 Scale it down to be no more than 
\begin_inset Formula $1500\times1500$
\end_inset

 (but not necessarily square), and read it into Matlab as a matrix 
\begin_inset Formula $A$
\end_inset

 with the 
\family typewriter
imread
\family default
 command (type 
\begin_inset Quotes eld
\end_inset


\family typewriter
doc imread
\family default

\begin_inset Quotes erd
\end_inset

 for instructions).
 
\end_layout

\begin_deeper
\begin_layout Enumerate
This is plotted on a semilog scale in Fig
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:svals"

\end_inset

, showing that the singular values 
\begin_inset Formula $\sigma_{i}$
\end_inset

 decrease 
\emph on
faster
\emph default
 than exponentially with 
\begin_inset Formula $i$
\end_inset

.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename svals.eps
	width 60col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:svals"

\end_inset

Distribution of the singular values 
\begin_inset Formula $\sigma_{i}$
\end_inset

 in the image of Fig.
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:stevenj"

\end_inset

, showing that they decrease faster than exponetially with 
\begin_inset Formula $i$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:stevenj"

\end_inset

 shows an image of a handsome fellow, both at full resolution (200 singular
 values), and using only 16 and 8 singular values.
 Even with just 8 singular values (4% of the data), the image is still at
 least somewhat recognizable.
 If the image were larger (this one is only 
\begin_inset Formula $282\times200$
\end_inset

) then it would probably compress even more.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename stevenj.jpg
	width 30col%

\end_inset


\begin_inset Graphics
	filename stevenj32.jpg
	width 30col%

\end_inset


\begin_inset Graphics
	filename stevenj8.jpg
	width 30col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:stevenj"

\end_inset

Left: full resolution image (albeit JPEG-compressed).
 Middle: 16% of the singular values.
 Right: 4% of the singular values.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Subsection*
Problem 2: QR and orthogonal bases (10+10+(5+5+5) pts)
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $A=QR$
\end_inset

, then 
\begin_inset Formula $B=RQ=Q^{*}AQ=Q^{-1}AQ$
\end_inset

 is a similarity transformation, and hence has the same eigenvalues as shown
 in the book.
 Numerically (and as explained in class and in lecture 28), doing this repeatedl
y for a Hermitian 
\begin_inset Formula $A$
\end_inset

 (the unshifted QR algorithm) converges to a diagonal matrix 
\begin_inset Formula $\Lambda$
\end_inset

 of the eigenvalues in descending order.
 To get the eigenvectors, we observe that if the 
\begin_inset Formula $Q$
\end_inset

 matrices from each step are 
\begin_inset Formula $Q_{1}$
\end_inset

, 
\begin_inset Formula $Q_{2}$
\end_inset

, and so on, then we are computing 
\begin_inset Formula $\cdots Q_{2}^{*}Q_{1}^{*}AQ_{1}Q_{2}\cdots=\Lambda$
\end_inset

, or 
\begin_inset Formula $A=Q\Lambda Q^{*}$
\end_inset

 where 
\begin_inset Formula $Q=Q_{1}Q_{2}\cdots$
\end_inset

.
 By comparison to the formula for diagonalizing 
\begin_inset Formula $A$
\end_inset

, the columns of 
\begin_inset Formula $Q$
\end_inset

 are the eigenvectors.
\end_layout

\begin_layout Enumerate
The easiest way to approach this problem is probably to look at the explicit
 construction of 
\begin_inset Formula $\hat{R}$
\end_inset

 via the Gram-Schmidt algorithms.
 By inspection, 
\begin_inset Formula $r_{ij}=q_{i}^{*}v_{j}$
\end_inset

 is zero if 
\begin_inset Formula $i$
\end_inset

 is even and 
\begin_inset Formula $j$
\end_inset

 is odd or vice-versa.
 Because of this, 
\begin_inset Formula $\hat{R}$
\end_inset

 will have a checkerboard pattern of nonzero values: 
\begin_inset Formula \[
\hat{R}=\left(\begin{array}{cccccccc}
\times &  & \times &  & \times &  & \times\\
 & \times &  & \times &  & \times &  & \times\\
 &  & \times &  & \times &  & \times\\
 &  &  & \times &  & \times &  & \times\\
 &  &  &  & \times &  & \times\\
 &  &  &  &  & \times &  & \times\\
 &  &  &  &  &  & \times\\
 &  &  &  &  &  &  & \times\end{array}\right).\]

\end_inset


\end_layout

\begin_layout Enumerate
Trefethen, problem 10.4:
\end_layout

\begin_deeper
\begin_layout Enumerate
e.g.
 consider 
\begin_inset Formula $\theta=\pi/2$
\end_inset

 (
\begin_inset Formula $c=0$
\end_inset

, 
\begin_inset Formula $s=1$
\end_inset

): 
\begin_inset Formula $Je_{1}=-e_{2}$
\end_inset

 and 
\begin_inset Formula $Je_{2}=e_{1}$
\end_inset

, while 
\begin_inset Formula $Fe_{1}=e_{2}$
\end_inset

 and 
\begin_inset Formula $Fe_{2}=e_{1}$
\end_inset

.
 
\begin_inset Formula $J$
\end_inset

 rotates clockwise in the plane by 
\begin_inset Formula $\theta$
\end_inset

.
 
\begin_inset Formula $F$
\end_inset

 is easier to interpret if we write it as 
\begin_inset Formula $J$
\end_inset

 multiplied on the right by 
\begin_inset Formula $[-1,0;0,1]$
\end_inset

: i.e., 
\begin_inset Formula $F$
\end_inset

 corresponds to a mirror reflection through the 
\begin_inset Formula $y$
\end_inset

 (
\begin_inset Formula $e_{2}$
\end_inset

) axis followed by clockwise rotation by 
\begin_inset Formula $\theta$
\end_inset

.
 More subtly, 
\begin_inset Formula $F$
\end_inset

 corresponds to reflection through a mirror plane corresponding to the 
\begin_inset Formula $y$
\end_inset

 axis rotated clockwise by 
\begin_inset Formula $\theta/2$
\end_inset

.
 That is, let 
\begin_inset Formula $c_{2}=\cos(\theta/2)$
\end_inset

 and 
\begin_inset Formula $s_{2}=\cos(\theta/2)$
\end_inset

, in which case (recalling the identities 
\begin_inset Formula $c_{2}^{2}-s_{2}^{2}=c$
\end_inset

, 
\begin_inset Formula $2s_{2}c_{2}=s$
\end_inset

): 
\begin_inset Formula \[
\left(\begin{array}{cc}
c_{2} & s_{2}\\
-s_{2} & c_{2}\end{array}\right)\left(\begin{array}{cc}
-1 & 0\\
0 & 1\end{array}\right)\left(\begin{array}{cc}
c_{2} & -s_{2}\\
s_{2} & c_{2}\end{array}\right)=\left(\begin{array}{cc}
-c_{2} & s_{2}\\
s_{2} & c_{2}\end{array}\right)\left(\begin{array}{cc}
c_{2} & -s_{2}\\
s_{2} & c_{2}\end{array}\right)=\left(\begin{array}{cc}
-c & s\\
s & c\end{array}\right)=F,\]

\end_inset

which shows that 
\begin_inset Formula $F$
\end_inset

 is reflection through the 
\begin_inset Formula $y$
\end_inset

 axis rotated by 
\begin_inset Formula $\theta/2$
\end_inset

.
\end_layout

\begin_layout Enumerate
The key thing is to focus on how we perform elimination under a single column
 of 
\begin_inset Formula $A$
\end_inset

, which we then repeat for each column.
 For Householder, this is done by a single Householder rotation.
 Here, since we are using 
\begin_inset Formula $2\times2$
\end_inset

 rotations, we have to eliminate under a column one number at a time: given
 2-component vector 
\begin_inset Formula $x=\left(\begin{array}{c}
a\\
b\end{array}\right)$
\end_inset

 into 
\begin_inset Formula $Jx=\left(\begin{array}{c}
\Vert x\Vert_{2}\\
0\end{array}\right)$
\end_inset

, where 
\begin_inset Formula $J$
\end_inset

 is clockwise rotation by 
\begin_inset Formula $\theta=\tan^{-1}(b/a)$
\end_inset

 [or, on a computer, 
\begin_inset Formula $\mbox{atan2}(b,a)$
\end_inset

].
 Then we just do this working 
\begin_inset Quotes eld
\end_inset

bottom-up
\begin_inset Quotes erd
\end_inset

 from the column: rotate the bottom two rows to introduce one zero, then
 the next two rows to introduce a second zero, etc.
\end_layout

\begin_layout Enumerate
The flops to compute the 
\begin_inset Formula $J$
\end_inset

 matrix itself are asymptotically irrelevant, because once 
\begin_inset Formula $J$
\end_inset

 is computed it is applied to many columns (all columns from the current
 one to the right).
 To multiply 
\begin_inset Formula $J$
\end_inset

 by a single 
\begin_inset Formula $2$
\end_inset

-component vector requires 4 multiplications and 2 additions, or 6 flops.
 That is, 6 flops per row per column of the matrix.
 In contrast, Householder requires each column 
\begin_inset Formula $x$
\end_inset

 to be rotated via 
\begin_inset Formula $x=x-2v(v^{*}x)$
\end_inset

.
 If 
\begin_inset Formula $x$
\end_inset

 has 
\begin_inset Formula $m$
\end_inset

 components, 
\begin_inset Formula $v^{*}x$
\end_inset

 requires 
\begin_inset Formula $m$
\end_inset

 multiplications and 
\begin_inset Formula $m-1$
\end_inset

 additions, multiplication by 
\begin_inset Formula $2v$
\end_inset

 requires 
\begin_inset Formula $m$
\end_inset

 more multiplications, and then subtraction from 
\begin_inset Formula $x$
\end_inset

 requires 
\begin_inset Formula $m$
\end_inset

 more additions, for 
\begin_inset Formula $4m-1$
\end_inset

 flops overall.
 That is, asymptotically 4 flops per row per column.
 The 6 flops of Givens is 50% more than the 4 of Householder.
\end_layout

\end_deeper
\begin_layout Subsection*
Problem 3: Schur fine (10 + 15 points)
\end_layout

\begin_layout Enumerate
First, let us show that 
\begin_inset Formula $T$
\end_inset

 is normal: substituting 
\begin_inset Formula $A=QTQ^{*}$
\end_inset

 into 
\begin_inset Formula $AA^{*}=A^{*}A$
\end_inset

 yields 
\begin_inset Formula $QTQ^{*}QT^{*}Q^{*}=QT^{*}Q^{*}QTQ^{*}$
\end_inset

 and hence (cancelling the 
\begin_inset Formula $Q$
\end_inset

s) 
\begin_inset Formula $TT^{*}=T^{*}T$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

The (1,1) entry of 
\begin_inset Formula $T^{*}T$
\end_inset

 is the squared 
\begin_inset Formula $L_{2}$
\end_inset

 norm (
\begin_inset Formula $\Vert\cdot\Vert_{2}^{2}$
\end_inset

) of the first column of 
\begin_inset Formula $T$
\end_inset

, i.e.
 
\begin_inset Formula $|t_{1,1}|^{2}$
\end_inset

 since 
\begin_inset Formula $T$
\end_inset

 is upper triangular, and the (1,1) entry of 
\begin_inset Formula $TT^{*}$
\end_inset

 is the squared 
\begin_inset Formula $L_{2}$
\end_inset

 norm of the first row of 
\begin_inset Formula $T$
\end_inset

, i.e.
 
\begin_inset Formula $\sum_{i}|t_{1,i}|^{2}$
\end_inset

.
 For these to be equal, we must obviously have 
\begin_inset Formula $t_{1,i}=0$
\end_inset

 for 
\begin_inset Formula $i>1$
\end_inset

, i.e.
 that the first row is diagonal.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

We proceed by induction.
 Suppose that the first 
\begin_inset Formula $j-1$
\end_inset

 rows of 
\begin_inset Formula $T$
\end_inset

 are diagonal, and we want to prove this of row 
\begin_inset Formula $j$
\end_inset

.
 The 
\begin_inset Formula $(j,j)$
\end_inset

 entry of 
\begin_inset Formula $T^{*}T$
\end_inset

 is the squared norm of the 
\begin_inset Formula $j$
\end_inset

-th column, i.e.
 
\begin_inset Formula $\sum_{i\leq j}|t_{i,j}|^{2}$
\end_inset

, but this is just 
\begin_inset Formula $|t_{j,j}|^{2}$
\end_inset

 since 
\begin_inset Formula $t_{i,j}=0$
\end_inset

 for 
\begin_inset Formula $i<j$
\end_inset

 by induction.
 The 
\begin_inset Formula $(j,j)$
\end_inset

 entry of 
\begin_inset Formula $TT^{*}$
\end_inset

 is the squared norm of the 
\begin_inset Formula $j$
\end_inset

-th row, i.e.
 
\begin_inset Formula $\sum_{i\geq j}|t_{j,i}|^{2}$
\end_inset

.
 For this to equal 
\begin_inset Formula $|t_{j,j}|^{2}$
\end_inset

, we must have 
\begin_inset Formula $t_{j,i}=0$
\end_inset

 for 
\begin_inset Formula $i>j$
\end_inset

, and hence the 
\begin_inset Formula $j$
\end_inset

-th row is diagonal.
 Q.E.D.
 
\end_layout

\begin_layout Enumerate
The eigenvalues are the roots of 
\begin_inset Formula $\det(T-\lambda I)=\prod_{i}(t_{i,i}-\lambda)=0$
\end_inset

---since 
\begin_inset Formula $T$
\end_inset

 is upper-triangular, the roots are obviously therefore 
\begin_inset Formula $\lambda=t_{i,i}$
\end_inset

 for 
\begin_inset Formula $i=1,\ldots,m$
\end_inset

.
 To get the eigenvector for a given 
\begin_inset Formula $\lambda=t_{i,i}$
\end_inset

, it suffices to compute the eigenvector 
\begin_inset Formula $x$
\end_inset

 of 
\begin_inset Formula $T$
\end_inset

, since the corresponding eigenvector of 
\begin_inset Formula $A$
\end_inset

 is 
\begin_inset Formula $Qx$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $x$
\end_inset

 satisfies
\begin_inset Formula \[
0=(T-t_{i,i}I)x=\left(\begin{array}{ccc}
T_{1} & u & B\\
 & 0 & v^{*}\\
 &  & T_{2}\end{array}\right)\left(\begin{array}{c}
x_{1}\\
\alpha\\
x_{2}\end{array}\right),\]

\end_inset

where we have broken up 
\begin_inset Formula $T-t_{i,i}I$
\end_inset

 into the first 
\begin_inset Formula $i-1$
\end_inset

 rows 
\begin_inset Formula $(T_{1}\, u\, B)$
\end_inset

, the 
\begin_inset Formula $i$
\end_inset

-th row (which has a zero on the diagonal), and the last 
\begin_inset Formula $m-i$
\end_inset

 rows 
\begin_inset Formula $T_{2}$
\end_inset

; similarly, we have broken up 
\begin_inset Formula $x$
\end_inset

 into the first 
\begin_inset Formula $i-1$
\end_inset

 rows 
\begin_inset Formula $x_{1}$
\end_inset

, the 
\begin_inset Formula $i$
\end_inset

-th row 
\begin_inset Formula $\alpha$
\end_inset

, and the last 
\begin_inset Formula $m-i$
\end_inset

 rows 
\begin_inset Formula $x_{2}$
\end_inset

.
 Here, 
\begin_inset Formula $T_{1}\in\mathbb{C}^{(i-1)\times(i-1)}$
\end_inset

 and 
\begin_inset Formula $T_{2}\in\mathbb{C}^{(m-i)\times(m-i)}$
\end_inset

 are upper-triangular, and are non-singular because by assumption there
 are no repeated eigenvalues and hence no other 
\begin_inset Formula $t_{j,j}$
\end_inset

 equals 
\begin_inset Formula $t_{i,i}$
\end_inset

.
 
\begin_inset Formula $u\in\mathbb{C}^{i-1}$
\end_inset

, 
\begin_inset Formula $v\in\mathbb{C}^{m-i}$
\end_inset

, and 
\begin_inset Formula $B\in\mathbb{C}^{(i-1)\times(m-i)}$
\end_inset

 come from the upper triangle of 
\begin_inset Formula $T$
\end_inset

 and can be anything.
 Taking the last 
\begin_inset Formula $m-i$
\end_inset

 rows of the above equation, we have 
\begin_inset Formula $T_{2}x_{2}=0$
\end_inset

, and hence 
\begin_inset Formula $x_{2}=0$
\end_inset

 since 
\begin_inset Formula $T_{2}$
\end_inset

 is invertible.
 Furthermore, we can scale 
\begin_inset Formula $x$
\end_inset

 arbitrarily, so we set 
\begin_inset Formula $\alpha=1$
\end_inset

.
 The first 
\begin_inset Formula $i-1$
\end_inset

 rows then give us the equation 
\begin_inset Formula $T_{1}x_{1}+u=0$
\end_inset

, which leads to an upper-triangular system 
\begin_inset Formula $T_{1}x_{1}=-u$
\end_inset

 that we can solve for 
\begin_inset Formula $x_{1}$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Now, let us count the number of operations.
 For the 
\begin_inset Formula $i$
\end_inset

-th eigenvalue 
\begin_inset Formula $t_{i,i}$
\end_inset

, to solve for 
\begin_inset Formula $x_{1}$
\end_inset

 requires 
\begin_inset Formula $\sim(i-1)^{2}\sim i^{2}$
\end_inset

 flops to do backsubstitution on an 
\begin_inset Formula $(i-1)\times(i-1)$
\end_inset

 system 
\begin_inset Formula $T_{1}x_{1}=-u$
\end_inset

.
 Then to compute the eigenvector 
\begin_inset Formula $Qx$
\end_inset

 of 
\begin_inset Formula $A$
\end_inset

 (exploiting the 
\begin_inset Formula $m-i$
\end_inset

 zeros in 
\begin_inset Formula $x$
\end_inset

) requires 
\begin_inset Formula $\sim2mi$
\end_inset

 flops.
 Adding these up for 
\begin_inset Formula $i=1\ldots m$
\end_inset

, we obtain 
\begin_inset Formula $\sum_{i=1}^{m}i^{2}\sim m^{3}/3$
\end_inset

, and 
\begin_inset Formula $2m\sum_{i=0}^{m-1}i\sim m^{3}$
\end_inset

, and hence the overall cost is 
\begin_inset Formula $\sim\frac{4}{3}m^{3}$
\end_inset

 flops (
\begin_inset Formula $K=4/3$
\end_inset

).
\end_layout

\end_body
\end_document
