#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble

\renewcommand{\vec}[1]{\mathbf{#1}}

\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand{\labelenumii}{(\roman{enumii})}

\newcommand{\tr}{\operatorname{tr}}
\newcommand{\sign}{\operatorname{sign}}

\renewcommand{\span}[1]{\operatorname{span}\langle #1 \rangle}
\newcommand{\fl}{\operatorname{fl}}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-15
\fontencoding T1
\font_roman times
\font_sans default
\font_typewriter mathptmx
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\topmargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
18.335 Midterm Solutions, Spring 2015
\end_layout

\begin_layout Subsection*
Problem 1: (10+20 points)
\end_layout

\begin_layout Enumerate
If we Taylor-expand around 
\begin_inset Formula $x_{\min}$
\end_inset

, we find 
\begin_inset Formula $f(x_{\min}+\delta)=f(x_{\min})+\delta^{2}f''(x_{\min})/2+O(\delta^{3})$
\end_inset

, where the 
\begin_inset Formula $O(\delta)$
\end_inset

 term vanishes at a minimum.
 Because 
\begin_inset Formula $\tilde{f}$
\end_inset

 is forwards-stable, 
\begin_inset Formula $\tilde{f}(x_{\min}+\delta)=f(x_{\min}+\delta)+|f(x_{\min}+\delta)|O(\epsilon)=f(x_{\min})+|f(x_{\min})|O(\epsilon)+O(\delta^{2})$
\end_inset

 (via Taylor expansion).
 This means that the roundoff-error 
\begin_inset Formula $O(\epsilon)$
\end_inset

 term can make 
\begin_inset Formula $\tilde{f}(x_{\min}+\delta)<f(x_{\min})$
\end_inset

 for 
\begin_inset Formula $\delta\in O(\sqrt{\epsilon})$
\end_inset

.
 Hence searching for the minimum will only locate 
\begin_inset Formula $x_{\min}$
\end_inset

 to within 
\begin_inset Formula $O(\sqrt{\epsilon})$
\end_inset

, and it is 
\emph on
not
\emph default
 stable.
 (Note that the only relevant question is forwards stability, since there
 is no input to the exhaustive minimization procedure.)
\end_layout

\begin_layout Enumerate
Here, we consider 
\begin_inset Formula $f(x)=Ax$
\end_inset

 and 
\begin_inset Formula $f_{i}(x)=a_{i}^{T}x$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
The problem with the argument is that there is in general a 
\emph on
different
\emph default
 
\begin_inset Formula $\tilde{x}$
\end_inset

 for each function 
\begin_inset Formula $f_{i}$
\end_inset

, whereas for 
\begin_inset Formula $f$
\end_inset

 to be backwards stable we need 
\begin_inset Formula $\tilde{f}(x)=f(\tilde{x})$
\end_inset

 with the 
\emph on
same
\emph default
 
\begin_inset Formula $\tilde{x}$
\end_inset

 for all components.
\end_layout

\begin_layout Enumerate
Consider 
\begin_inset Formula $A=(1,\pi)^{T}$
\end_inset

, for which 
\begin_inset Formula $f(x)=(x,\pi x)^{T}$
\end_inset

.
 In floating-point arithmetic, 
\begin_inset Formula $\tilde{f}(x)$
\end_inset

 will always give an output with two floating-point components, i.e.
 two components with a rational ratio, and hence 
\begin_inset Formula $\tilde{f}(x)\ne f(\tilde{x})$
\end_inset

 for any 
\begin_inset Formula $\tilde{x}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Subsection*
Problem 2: (10+10+10 points)
\end_layout

\begin_layout Standard
Here, we are comparing 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

 with the first 
\begin_inset Formula $n$
\end_inset

 components of the 
\begin_inset Formula $(n+1)$
\end_inset

-st column of 
\begin_inset Formula $\breve{R}$
\end_inset

.
 The two are equal in exact arithmetic for any QR algorithm applied to the
 augmented matrix 
\begin_inset Formula $\breve{A}=(A,b)$
\end_inset

.
 To compare them in floating-point arithmetic, for simplicity I will assume
 that dot products 
\begin_inset Formula $q^{*}b$
\end_inset

 are computed with the same algorithm as the components of matrix-vector
 products 
\begin_inset Formula $Q^{*}b$
\end_inset

.
 The main point of this problem is to recognize that the augmented-matrix
 approach 
\emph on
only makes a big difference for MGS
\emph default
 in practice.
\end_layout

\begin_layout Enumerate
In CGS, the first 
\begin_inset Formula $n$
\end_inset

 components of the last column of 
\begin_inset Formula $\breve{R}$
\end_inset

 will be 
\begin_inset Formula $q_{i}^{*}b$
\end_inset

.
 This is identical to what is computed by 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

, so the two will be 
\emph on
exactly
\emph default
 the same even in floating-point arithmetic.
 (Of course, CGS is unstable, so the two methods will be equally 
\emph on
bad
\emph default
.)
\end_layout

\begin_layout Enumerate
In MGS, to get the first 
\begin_inset Formula $n$
\end_inset

 components of the last column of 
\begin_inset Formula $\breve{R}$
\end_inset

, we first compute 
\begin_inset Formula $r_{1,n+1}=q_{1}^{*}b$
\end_inset

 exactly as in the first component of 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

, so that component will be identical.
 However, subsequent components will be different (in floating-point arithmetic)
, because we first subtract the 
\begin_inset Formula $q_{1}$
\end_inset

 component from 
\begin_inset Formula $b$
\end_inset

 before dotting with 
\begin_inset Formula $q_{2}$
\end_inset

, etcetera.
 This will be more accurate for the purpose of solving the least-squares
 problem because the floating-point loss-of-orthogonality means that 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

 may not be close to 
\begin_inset Formula $(\hat{Q}^{*}\hat{Q})^{-1}\hat{Q}^{*}b$
\end_inset

 in the presence of roundoff error; in contrast, the backwards-stability
 of MGS will guarantee the backwards stability of 
\begin_inset Formula $\hat{R}\hat{x}=\hat{Q}^{*}b$
\end_inset

 as stated (but not proved) in Trefethen.
 (The proof, as I mentioned in class, proceeds by showing that MGS is exactly
 equivalent, even with roundoff error, to Householder on a modified input
 matrix, and Householder by construction—as proved in homework—provides
 a backwards-stable product of 
\begin_inset Formula $\breve{A}$
\end_inset

 by 
\begin_inset Formula $\breve{Q}^{*}$
\end_inset

.
 You are not expected to prove this here, however.)
\end_layout

\begin_layout Enumerate
In Householder, we get the first 
\begin_inset Formula $n$
\end_inset

 components of the last column of 
\begin_inset Formula $\breve{R}$
\end_inset

 by multiplying 
\begin_inset Formula $b$
\end_inset

 by a sequence of Householder reflectors: 
\begin_inset Formula $I-2v_{k}v_{k}^{*}$
\end_inset

.
 However, because of the way 
\begin_inset Formula $Q$
\end_inset

 is stored implicitly for Householder (at least, for the algorithm as described
 in class and in Trefethen lecture 10), this is 
\emph on
exactly
\emph default
 how 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

 is computed from the Householder reflectors, so we will get the same thing
 in floating-point arithmetic.
 (Note that there is a slight subtlety because 
\begin_inset Formula $\hat{Q}$
\end_inset

 is 
\begin_inset Formula $m\times n$
\end_inset

 while the product of the Householder reflections gives the 
\begin_inset Formula $m\times m$
\end_inset

 matrix 
\begin_inset Formula $Q$
\end_inset

.
 But we would just multiply 
\begin_inset Formula $Q^{*}b$
\end_inset

 and then take the first 
\begin_inset Formula $n$
\end_inset

 components in order to get 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

.)
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

[On the other hand, not all computing environments give you easy access
 to the implicit storage for 
\begin_inset Formula $Q$
\end_inset

.
 For example, the 
\family typewriter
qr(A)
\family default
 function in Matlab or Julia returns 
\begin_inset Formula $Q$
\end_inset

 as an ordinary dense matrix, making it somewhat preferable to use the augmented
 scheme if only because the explicit computation of 
\begin_inset Formula $Q$
\end_inset

 is unnecessarily expensive---it is still backwards stable as argued in
 Trefethen.
 However, the 
\family typewriter
qrfact(A)
\family default
 function in Julia returns a representation of the Householder reflectors
 in the 
\begin_inset Quotes eld
\end_inset

compact WY
\begin_inset Quotes erd
\end_inset

 format (such that, when you multiply the resulting 
\begin_inset Formula $\hat{Q}^{*}b$
\end_inset

 in Julia, it effectively performs the reflections—this is a more cache-friendly
 version of the reflector algorithm in Trefethen).
 NumPy also provides partial support for this via the 
\family typewriter
qr(A, mode='raw')
\family default
 interface.
 If you call LAPACK directly from C or Fortran, of course, you have little
 choice but to deal with these low-level details.]
\end_layout

\begin_layout Subsection*
Problem 3: (10+20+10 points)
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $Ax_{k}=\lambda_{k}Bx_{k}$
\end_inset

, then 
\begin_inset Formula $x_{k}^{*}Ax_{k}=\lambda_{k}x_{k}^{*}Bx_{k}=(A^{*}x_{k})^{*}x_{k}=(Ax_{k})^{*}x_{k}=(\lambda_{k}Bx_{k})^{*}x_{k}=\overline{\lambda_{k}}x_{k}^{*}Bx_{k}$
\end_inset

 (where we have used the Hermiticity of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

).
 Hence 
\begin_inset Formula $(\lambda_{k}-\overline{\lambda_{k}})x_{k}^{*}Bx_{k}=0$
\end_inset

, and since 
\begin_inset Formula $B$
\end_inset

 is positive definite we have 
\begin_inset Formula $x_{k}^{*}Bx_{k}>0$
\end_inset

, so 
\begin_inset Formula $\lambda_{k}=\overline{\lambda_{k}}$
\end_inset

 and 
\begin_inset Formula $\lambda_{k}$
\end_inset

 is real.
 Similarly, if 
\begin_inset Formula $i\ne j$
\end_inset

 and 
\begin_inset Formula $\lambda_{i}\ne\lambda_{j}$
\end_inset

, we have 
\begin_inset Formula $x_{i}^{*}Ax_{j}=\lambda_{j}x_{i}^{*}Bx_{j}=\lambda_{i}x_{i}^{*}Bx_{j}$
\end_inset

, and we obtain 
\begin_inset Formula $x_{i}^{*}Bx_{j}=0$
\end_inset

.
 (See below for an alternate proof: we can change basis to show that 
\begin_inset Formula $B^{-1}A$
\end_inset

 is 
\emph on
similar
\emph default
 to a Hermitian matrix.
 A third proof is to show that 
\begin_inset Formula $B^{-1}A$
\end_inset

 is 
\begin_inset Quotes eld
\end_inset

Hermitian
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

self-adjoint
\begin_inset Quotes erd
\end_inset

 under a modified inner product 
\begin_inset Formula $\langle x,y\rangle_{B}=x^{*}By$
\end_inset

, but we haven't generalized the concept of Hermiticity in this way in 18.335.)
\end_layout

\begin_layout Enumerate
Naively, we can just apply MGS to 
\begin_inset Formula $B^{-1}A$
\end_inset

, except that we replace 
\begin_inset Formula $x^{*}y$
\end_inset

 dot products with 
\begin_inset Formula $x^{*}By$
\end_inset

 (this also means that 
\begin_inset Formula $\Vert x\Vert_{2}$
\end_inset

 is replaced by 
\begin_inset Formula $\Vert x\Vert_{B}=\sqrt{x^{*}Bx}$
\end_inset

).
 Hence we replace 
\begin_inset Formula $q_{j}$
\end_inset

 with 
\begin_inset Formula $s_{j}$
\end_inset

 (the 
\begin_inset Formula $j$
\end_inset

-th column of 
\begin_inset Formula $S$
\end_inset

).
 The only problem is that this will require the 
\begin_inset Formula $\Theta(m^{2})$
\end_inset

 operation 
\begin_inset Formula $Bv_{j}$
\end_inset

 in the innermost loop, executed 
\begin_inset Formula $\Theta(m^{2})$
\end_inset

 times, so the whole algorithm will be 
\begin_inset Formula $\Theta(m^{4})$
\end_inset

.
 Instead, we realize that 
\begin_inset Formula $v_{j}=(B^{-1}A)_{j}=B^{-1}a_{j}$
\end_inset

 (where 
\begin_inset Formula $a_{j}$
\end_inset

 is the 
\begin_inset Formula $j$
\end_inset

-th column of 
\begin_inset Formula $a$
\end_inset

) and cancel this 
\begin_inset Formula $B^{-1}$
\end_inset

 factor with the new 
\begin_inset Formula $B$
\end_inset

 factor in the dot product.
 In particular, let 
\begin_inset Formula $\breve{v}_{j}=Bv_{j}$
\end_inset

 and 
\begin_inset Formula $\breve{s}_{j}=Bs_{j}$
\end_inset

.
 Then our MGS 
\begin_inset Quotes eld
\end_inset

SR
\begin_inset Quotes erd
\end_inset

 algorithm becomes, for 
\begin_inset Formula $j=1$
\end_inset

 to 
\begin_inset Formula $n$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $\breve{v}_{j}=a_{j}$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $i=1$
\end_inset

 to 
\begin_inset Formula $j-1$
\end_inset

, do: 
\begin_inset Formula $r_{ij}=s_{i}^{*}\breve{v}_{j}$
\end_inset

, and 
\begin_inset Formula $\breve{v}_{j}\leftarrow\breve{v}_{j}-r_{ij}\breve{s}_{i}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Compute 
\begin_inset Formula $v_{j}=B^{-1}\breve{v}_{j}$
\end_inset

 (the best way is via Cholesky factors of 
\begin_inset Formula $B$
\end_inset

; as usual there is no need to compute 
\begin_inset Formula $B^{-1}$
\end_inset

 explicitly).
\end_layout

\begin_layout Enumerate
Compute 
\begin_inset Formula $r_{jj}=\Vert v_{j}\Vert_{B}$
\end_inset

, and 
\begin_inset Formula $s_{j}=v_{j}/r_{jj}$
\end_inset

.
\end_layout

\begin_layout Standard
Alternatively, we can compute 
\begin_inset Formula $s_{i}^{*}Bv_{j}=(Bs_{i})^{*}v_{j}=\breve{s}_{i}^{*}v_{j}$
\end_inset

, and work with 
\begin_inset Formula $v_{j}$
\end_inset

 rather than 
\begin_inset Formula $\breve{v}_{j}$
\end_inset

.
 Another, perhaps less obvious, alternative is:
\end_layout

\begin_layout Enumerate
Compute the Cholesky factorization 
\begin_inset Formula $B=LL^{*}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Compute the ordinary QR factorization (via ordinary MGS or Householder)
 
\begin_inset Formula $L^{-1}A=QR$
\end_inset

.
\end_layout

\begin_layout Enumerate
Let 
\begin_inset Formula $S=(L^{*})^{-1}Q=L^{-*}Q$
\end_inset

.
 Hence 
\begin_inset Formula $L^{-*}L^{-1}A=(LL^{*})^{-1}A=B^{-1}A=SR$
\end_inset

, and 
\begin_inset Formula $S$
\end_inset

 satisfies 
\begin_inset Formula $S^{*}BS=Q^{*}L^{-1}(LL^{*})L^{-*}Q=Q^{*}Q=I$
\end_inset

.
\end_layout

\begin_layout Standard
The basic reason why this Cholesky approach works is it represents a 
\emph on
change of basis
\emph default
 to a coordinate system in which 
\begin_inset Formula $B=I$
\end_inset

.
 That is, for any vector 
\begin_inset Formula $x$
\end_inset

, let 
\begin_inset Formula $x'=L^{*}x$
\end_inset

, in which case 
\begin_inset Formula $x'^{*}y'=xLL^{*}y=x^{*}By$
\end_inset

.
 In the new basis, 
\begin_inset Formula $B^{-1}A$
\end_inset

 becomes 
\begin_inset Formula $L^{*}B^{-1}AL^{-*}=L^{-1}AL^{-*}$
\end_inset

 …which is now Hermitian in the usal sense, so we get the results of part
 (a) for 
\begin_inset Quotes eld
\end_inset

free
\begin_inset Quotes erd
\end_inset

 and we can apply all our familiar linear-algebra algorithms for Hermitian
 matrices.
 If we form the QR factorization in this basis, i.e.
 
\begin_inset Formula $L^{-1}AL^{-*}=Q'R'$
\end_inset

, and then change 
\emph on
back
\emph default
 to the original basis, we get 
\begin_inset Formula $B^{-1}A=L^{-*}Q'R'L^{*}=SR$
\end_inset

 where 
\begin_inset Formula $S=L^{-*}Q$
\end_inset

 (satisfying 
\begin_inset Formula $S^{*}BS=I$
\end_inset

 as above) and 
\begin_inset Formula $R=R'L^{*}$
\end_inset

 (note that 
\begin_inset Formula $R$
\end_inset

 is upper triangular).
 [Instead of the Cholesky factorization, we could also write 
\begin_inset Formula $B=B^{1/2}B^{1/2}$
\end_inset

 and make the change of basis 
\begin_inset Formula $x'=B^{1/2}x$
\end_inset

; this gives analogous results, but matrix square roots are much more expensive
 to compute than Cholesky.]
\end_layout

\end_deeper
\begin_layout Enumerate
It should converge to 
\begin_inset Formula $S\to X$
\end_inset

 (the matrix of eigenvectors, in descending order of 
\begin_inset Formula $|\lambda|$
\end_inset

), up to some arbitrary scaling.
 If we normalized 
\begin_inset Formula $X^{*}BX=I$
\end_inset

 (as we are entitled to do, from above), then 
\begin_inset Formula $S=X\Phi$
\end_inset

 where 
\begin_inset Formula $\Phi$
\end_inset

 is a diagonal matrix of phase factors 
\begin_inset Formula $e^{i\phi}$
\end_inset

.
 The argument is essentially identical to the reasoning from class that
 we used for the ordinary QR algorithm (or, equivalently, for simultaneous
 power iteration).
 The 
\begin_inset Formula $j$
\end_inset

-th column of 
\begin_inset Formula $(B^{-1}A)^{k}$
\end_inset

 is 
\begin_inset Formula $(B^{-1}A)^{k}e_{j}=\sum_{\ell}\lambda_{\ell}^{k}c_{\ell}x_{j}$
\end_inset

, where 
\begin_inset Formula $e_{j}=\sum_{\ell}c_{\ell}x_{j}$
\end_inset

, i.e.
 
\begin_inset Formula $c_{\ell}=x_{j}^{*}Be_{j}$
\end_inset

 (assumed to be generically 
\begin_inset Formula $\ne0$
\end_inset

).
 As 
\begin_inset Formula $k\to\infty$
\end_inset

, this is dominated by the 
\begin_inset Formula $\lambda_{1}^{k}$
\end_inset

 term, so we get 
\begin_inset Formula $s_{1}\sim x_{1}$
\end_inset

.
 To get 
\begin_inset Formula $s_{2}$
\end_inset

, however, we first project out the 
\begin_inset Formula $s_{1}$
\end_inset

 term, hence what remains is dominated by the 
\begin_inset Formula $\lambda^{2}{}^{k}$
\end_inset

 term and we get 
\begin_inset Formula $s_{2}\sim x_{2}$
\end_inset

.
 Similarly for the remaining columns, giving 
\begin_inset Formula $s_{j}\sim x_{k}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Standard
Note that it is crucial that we use the 
\begin_inset Formula $B$
\end_inset

 inner product here in the SR factorization, not the ordinary QR factorization.
 The QR factorization would give the Schur factors of 
\begin_inset Formula $B^{-1}A$
\end_inset

 because 
\begin_inset Formula $x_{i}^{*}x_{j}\ne0$
\end_inset

.
 For example, consider the second column 
\begin_inset Formula $v_{2}=(B^{-1}A)^{k}e_{2}\approx\lambda_{1}^{k}c_{1}x_{1}+\lambda_{2}^{k}c_{2}x_{2}$
\end_inset

, with 
\begin_inset Formula $q_{1}=x_{1}/\Vert x_{1}\Vert_{2}$
\end_inset

.
 When we perform e.g.
 Gram-Schmidt on this column to project out the 
\begin_inset Formula $q_{1}$
\end_inset

 component (for ordinary QR), we take 
\begin_inset Formula $v_{2}-q_{1}q_{1}^{*}v_{2}\approx\lambda_{2}^{k}c_{2}(x_{2}-q_{1}q_{1}^{*}x_{2})$
\end_inset

, where the 
\begin_inset Formula $\lambda_{1}^{k}$
\end_inset

 term exactly cancels.
 Notice that what remains is 
\emph on
not
\emph default
 proportional to 
\begin_inset Formula $x_{2}$
\end_inset

, but also has an 
\begin_inset Formula $x_{1}$
\end_inset

 component of magnitude 
\begin_inset Formula $\sim x_{1}^{*}x_{2}$
\end_inset

, which is not small.
 In general, the 
\begin_inset Formula $j$
\end_inset

-th column will have components of 
\begin_inset Formula $x_{1},\ldots,x_{j}$
\end_inset

 with similar magnitudes, and hence we would get a Schur factorization 
\begin_inset Formula $T=Q^{*}AQ$
\end_inset

 from 
\begin_inset Formula $Q$
\end_inset

.
 (This was a question on an exam from a previous year.) Instead, by using
 the SR factorization, we take 
\begin_inset Formula $v_{2}-s_{1}s_{1}^{*}Bv_{2}$
\end_inset

 etcetera and the cross terms vanish.
\end_layout

\begin_layout Standard
[As with the QR algorithm, this procedure would fail utterly in the presence
 of roundoff errors, because everything except for the 
\begin_inset Formula $\lambda_{1}^{k}$
\end_inset

 components would be lost to roundoff as 
\begin_inset Formula $k\to\infty$
\end_inset

.
 But one could devise a QR-like teration to construct the same 
\begin_inset Formula $S$
\end_inset

 implicitly without forming 
\begin_inset Formula $(B^{-1}A)^{k}$
\end_inset

.
 In practice, there are a variety of efficient algorithms for generalized
 eigenproblems, including the Hermitian case considered here, and LAPACK
 provides good implementations.
 The key thing is that one should preserve the Hermitian structure by keeping
 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 around, rather than discarding it and working with 
\begin_inset Formula $B^{-1}A$
\end_inset

.
 In practice, one need not even compute 
\begin_inset Formula $B^{-1}$
\end_inset

, e.g.
 in Lanczos-like algorithms for 
\begin_inset Formula $Ax=\lambda Bx$
\end_inset

.]
\end_layout

\end_deeper
\end_body
\end_document
