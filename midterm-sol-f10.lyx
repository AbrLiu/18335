#LyX 1.6.2 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble

\renewcommand{\vec}[1]{\mathbf{#1}}

\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand{\labelenumii}{(\roman{enumii})}

\newcommand{\tr}{\operatorname{tr}}
\newcommand{\sign}{\operatorname{sign}}
\end_preamble
\use_default_options false
\language english
\inputencoding auto
\font_roman times
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 2
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\topmargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Section*
18.335 Midterm Solutions, Fall 2010
\end_layout

\begin_layout Subsection*
Problem 1: SVD Stability (20 points)
\end_layout

\begin_layout Standard
Consider the problem of computing the SVD 
\begin_inset Formula $A=U\Sigma V^{*}$
\end_inset

 from a matrix 
\begin_inset Formula $A$
\end_inset

 (the input).
 In this case, we are computing the function 
\begin_inset Formula $f(A)=(U,\Sigma,V)$
\end_inset

: the outputs are of the SVD are 3 matrices, i.e.
 a triple 
\begin_inset Formula $(U,\Sigma,V)$
\end_inset

 and 
\emph on
not
\emph default
 just the product 
\begin_inset Formula $U\Sigma V^{*}$
\end_inset

.
\end_layout

\begin_layout Enumerate
In floating-point, we compute 
\begin_inset Formula $\tilde{f}(A)=(\tilde{U},\tilde{\Sigma},\tilde{V})$
\end_inset

.
 If this were backwards stable, there would be some 
\begin_inset Formula $\delta A$
\end_inset

 with 
\begin_inset Formula $\Vert\delta A\Vert=\Vert A\Vert O(\epsilon_{\mbox{machine}})$
\end_inset

 such that 
\begin_inset Formula $f(A+\delta A)=(\tilde{U},\tilde{\Sigma},\tilde{V})$
\end_inset

, i.e.
 
\begin_inset Formula $(\tilde{U},\tilde{\Sigma},\tilde{V})$
\end_inset

 are the exact SVD of 
\begin_inset Formula $A+\delta A$
\end_inset

.
 Note that this is a much stronger statement than simply that 
\begin_inset Formula $A+\delta A=\tilde{U}\tilde{\Sigma}\tilde{V}^{*}$
\end_inset

!
\end_layout

\begin_layout Enumerate
For it to be backwards stable, 
\begin_inset Formula $(\tilde{U},\tilde{\Sigma},\tilde{V})$
\end_inset

 would have to be the exact SVD of 
\emph on
something
\emph default
, which would mean that 
\begin_inset Formula $\tilde{U}$
\end_inset

 and 
\begin_inset Formula $\tilde{V}$
\end_inset

 would have to be exactly unitary, which is extremely unlikely under roundoff
 errors.
\end_layout

\begin_layout Enumerate
If the exact SVD of 
\begin_inset Formula $A+\delta A$
\end_inset

 is 
\begin_inset Formula $f(A+\delta A)=(U',\Sigma',V')$
\end_inset

, then stability would mean that, in addition to 
\begin_inset Formula $\Vert\delta A\Vert=\Vert A\Vert O(\epsilon_{\mbox{machine}})$
\end_inset

, we would also have to have 
\begin_inset Formula $\Vert(U',\Sigma',V')-(\tilde{U},\tilde{\Sigma},\tilde{V})\Vert=\Vert(U,\Sigma,V)\Vert O(\epsilon_{\mbox{machine}})$
\end_inset

, for any norm 
\begin_inset Formula $\Vert(U,\Sigma,V)\Vert$
\end_inset

 on triples 
\begin_inset Formula $(U,\Sigma,V)$
\end_inset

.
 For example, we could use 
\begin_inset Formula $\Vert(U,\Sigma,V)\Vert=\max(\Vert U\Vert,\Vert\Sigma\Vert,\Vert V\Vert)$
\end_inset

 for any matrix norm.
 e.g.
 for the 
\begin_inset Formula $L_{2}$
\end_inset

 induced norm, 
\begin_inset Formula $\Vert U\Vert=\Vert V\Vert=1$
\end_inset

 and 
\begin_inset Formula $\Vert\Sigma\Vert=\Vert A\Vert$
\end_inset

, so we would have 
\begin_inset Formula \[
\max(\Vert U'-\tilde{U}\Vert,\Vert\Sigma'-\tilde{\Sigma}\Vert,\Vert V-\tilde{V}\Vert)=\Vert A\Vert O(\epsilon_{\mbox{machine}}),\]

\end_inset

or equivalently
\begin_inset Formula \[
\Vert U'-\tilde{U}\Vert=\Vert A\Vert O(\epsilon_{\mbox{machine}}),\]

\end_inset


\begin_inset Formula \[
\Vert\Sigma'-\tilde{\Sigma}\Vert=\Vert A\Vert O(\epsilon_{\mbox{machine}}),\]

\end_inset


\begin_inset Formula \[
\Vert V'-\tilde{V}\Vert=\Vert A\Vert O(\epsilon_{\mbox{machine}}).\]

\end_inset

It is tempting to instead put 
\begin_inset Formula $\Vert U\Vert O(\epsilon_{\mbox{machine}})$
\end_inset

, 
\begin_inset Formula $\Vert\Sigma\Vert O(\epsilon_{\mbox{machine}})$
\end_inset

, and 
\begin_inset Formula $\Vert V\Vert O(\epsilon_{\mbox{machine}})$
\end_inset

 on the right-hand sides, but this appears to be a much stronger condition
 (which may well be true in SVD algorithms, but is not what was given).
\end_layout

\begin_layout Subsection*
Problem 2: Least squares (20 points)
\end_layout

\begin_layout Standard
Suppose that we want to solve the 
\series bold
weighted least-squares
\series default
 problem 
\begin_inset Formula \[
\min_{x}\Vert B^{-1}(Ax-b)\Vert_{2}\]

\end_inset

where 
\begin_inset Formula $B$
\end_inset

 (
\begin_inset Formula $m\times m$
\end_inset

) is a nonsingular square matrix and 
\begin_inset Formula $A$
\end_inset

 (
\begin_inset Formula $m\times n$
\end_inset

) has full column rank.
 This can be solved a bit trivially because we can write it down as an ordinary
 least squares problem 
\begin_inset Formula \[
\min_{x}\Vert A'x-b')\Vert_{2}\]

\end_inset

for 
\begin_inset Formula $A'=B^{-1}A$
\end_inset

 and 
\begin_inset Formula $b'=B^{-1}b$
\end_inset

.
\end_layout

\begin_layout Enumerate
The normal equations are 
\begin_inset Formula $A'^{*}A'x=A'^{*}b'$
\end_inset

 from ordinary least-squares, i.e.
\begin_inset Formula \[
A^{*}\left(B^{-1}\right)^{*}B^{-1}Ax=A^{*}\left(B^{-1}\right)^{*}B^{-1}x.\]

\end_inset


\end_layout

\begin_layout Enumerate
We can solve it exactly as for the ordinary least-squares problem in 
\begin_inset Formula $A'$
\end_inset

 and 
\begin_inset Formula $b'$
\end_inset

.
 First, compute 
\begin_inset Formula $A'=U^{-1}L^{-1}A$
\end_inset

 by backsubstitution, where 
\begin_inset Formula $B=LU$
\end_inset

 e.g.
 by Gaussian elimination.
 Then QR factorize 
\begin_inset Formula $A'=QR$
\end_inset

 e.g.
 by Householder, then solve 
\begin_inset Formula $R^{*}x=Q^{*}b'=Q^{*}U^{-1}L^{-1}b$
\end_inset

.
 As in ordinary QR for least-squares, all of the squareing of 
\begin_inset Formula $A'$
\end_inset

 has been cancelled analytically, and both the right and left-hand sides
 of this equation are multiplications of things with 
\begin_inset Formula $\kappa(R)=\kappa(B^{-1}A)$
\end_inset

 and 
\begin_inset Formula $\kappa(B^{-1})$
\end_inset

, respectively.
\end_layout

\begin_layout Standard
I should mention that there are even more efficient/accurate ways to solve
 this problem than doing ordinary least-squares with 
\begin_inset Formula $B^{-1}A$
\end_inset

.
 LAPACK provides something called a 
\begin_inset Quotes eld
\end_inset

generalized QR
\begin_inset Quotes erd
\end_inset

 factorization 
\begin_inset Formula $A=QR$
\end_inset

, 
\begin_inset Formula $B=QTZ$
\end_inset

 for this, where 
\begin_inset Formula $Z$
\end_inset

 is also unitary and 
\begin_inset Formula $T$
\end_inset

 is upper triangular, to avoid the necessity of a separate LU factorization
 of 
\begin_inset Formula $B$
\end_inset

.
\end_layout

\begin_layout Subsection*
Problem 3: Eigenvalues (20 points)
\end_layout

\begin_layout Enumerate
Suppose our initial guess is expanded in the eigenvectors 
\begin_inset Formula $q_{i}$
\end_inset

 as 
\begin_inset Formula $x_{1}=c_{1}q_{1}+c_{2}q_{2}+\cdots$
\end_inset

 (where for a random 
\begin_inset Formula $x_{1}$
\end_inset

 all the 
\begin_inset Formula $c_{i}$
\end_inset

 are 
\begin_inset Formula $\neq0$
\end_inset

 in general), in which case 
\begin_inset Formula $x_{n}=(c_{1}\lambda_{1}^{n}q_{1}+c_{2}\lambda_{2}^{n}q_{2}+\cdots)/\Vert\cdots\Vert$
\end_inset

.
 If 
\begin_inset Formula $|\lambda_{1}|=|\lambda_{2}|$
\end_inset

, then the 
\begin_inset Formula $q_{1}$
\end_inset

 and 
\begin_inset Formula $q_{2}$
\end_inset

 terms will grow at the same rate, and it will never be dominated by 
\begin_inset Formula $q_{1}$
\end_inset

 alone---
\begin_inset Formula $x_{n}$
\end_inset

 will 
\begin_inset Quotes eld
\end_inset

bounce around
\begin_inset Quotes erd
\end_inset

 in a two-dimensional subspace spanned by 
\begin_inset Formula $q_{1}$
\end_inset

 and 
\begin_inset Formula $q_{2}$
\end_inset

.
 Note that the algorithm will 
\emph on
not
\emph default
 in general converge: for example, if 
\begin_inset Formula $\lambda_{2}=-\lambda_{1}$
\end_inset

, then the relative signs of the 
\begin_inset Formula $q_{1}$
\end_inset

 and 
\begin_inset Formula $q_{2}$
\end_inset

 terms will oscillate.
 (More generally, 
\begin_inset Formula $\lambda_{2}=e^{i\phi}\lambda_{1}$
\end_inset

 for some phase 
\begin_inset Formula $\phi$
\end_inset

, and the 
\begin_inset Formula $q_{2}$
\end_inset

 term will rotate in phase by 
\begin_inset Formula $\phi$
\end_inset

 relative to 
\begin_inset Formula $q_{1}$
\end_inset

 on each step.) 
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

However, if 
\begin_inset Formula $\lambda_{1}=\lambda_{2}$
\end_inset

, then 
\begin_inset Formula $x_{n}=[\lambda_{1}^{n}(c_{1}q_{1}+c_{2}q_{2})+O(|\lambda_{3}/\lambda_{1}|^{n})]/\Vert\cdots\Vert$
\end_inset

, and 
\begin_inset Formula $x_{n}$
\end_inset

 therefore becomes parallel to 
\begin_inset Formula $c_{1}q_{1}+c_{2}q_{2}$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

 (assuming 
\begin_inset Formula $|\lambda_{3}|<|\lambda_{1}|$
\end_inset

).
 But both 
\begin_inset Formula $q_{1}$
\end_inset

 and 
\begin_inset Formula $q_{2}$
\end_inset

 are eigenvectors with the same eigenvalue 
\begin_inset Formula $\lambda_{1}$
\end_inset

, so 
\begin_inset Formula $c_{1}q_{1}+c_{2}q_{2}$
\end_inset

 is also an eigenvector of 
\begin_inset Formula $\lambda_{1}$
\end_inset

.
 Therefore, this is not a problem: we still get an eigenvector of 
\begin_inset Formula $\lambda_{1}$
\end_inset

.
 Equivalently, all of the eigenvectors for 
\begin_inset Formula $\lambda=\lambda_{1}$
\end_inset

 form a subspace which is magnified relative to other eigenvalues by multiplying
 repeatedly by 
\begin_inset Formula $A$
\end_inset

, as long as other eigenvalues 
\begin_inset Formula $\neq\lambda_{1}$
\end_inset

 have smaller magnitude.
 
\end_layout

\begin_layout Enumerate
Applying Lanczos to 
\begin_inset Formula $(A-\mu I)^{2}$
\end_inset

 is computationally easy because we just need to multiply by 
\begin_inset Formula $(A-\mu I)$
\end_inset

 twice in each step (cheap if 
\begin_inset Formula $A$
\end_inset

 is sparse, cost 
\begin_inset Formula $\sim$
\end_inset

 #nonzeros).
 However, we have squared the condition number of 
\begin_inset Formula $A-\mu I$
\end_inset

, and thus we square the rate at which the 
\emph on
largest
\emph default
-
\begin_inset Formula $|\lambda|$
\end_inset

 eigenvalues appear in the Krylov space, correspondingly slowing the rate
 (~ doubling the number of iterations) at which we get the 
\emph on
smallest
\emph default
 eigenvalue (the one closest to 
\begin_inset Formula $\mu$
\end_inset

), and exacerbating problems with roundoff errors and ghost eigenvalues.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

On the other hand, 
\begin_inset Formula $(A-\mu I)^{-1}$
\end_inset

 does not square any condition numbers, since the desired eigenvalue is
 now the largest-magnitude one, there should be no problem with ghost eigenvalue
s or roundoff (from homework) and Lanczos should converge well.
 However, we now have to multiply by 
\begin_inset Formula $(A-\mu I)^{-1}$
\end_inset

 at each step, which means that on each step we need to solve a linear system
 with 
\begin_inset Formula $A-\mu I$
\end_inset

.
 If 
\begin_inset Formula $A$
\end_inset

 is amenable to sparse-direct factorization, then we can do this 
\emph on
once
\emph default
 and re-use it throughout the Lanczos process (only somewhat slower than
 multiplying by 
\begin_inset Formula $A$
\end_inset

 repeatedly, since the sparse-direct factorization generally loses some
 sparsity).
 If sparse-direct solvers are impractical and we have to use an iterative
 solver like GMRES etcetera, then we have the expense of repeating this
 iterative process on each step of Lanczos.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Because of these tradeoffs, neither method is ideal for computing interior
 the eigenvalue closest to 
\begin_inset Formula $\mu$
\end_inset

---computing interior eigenvalues is tricky.
\end_layout

\end_body
\end_document
